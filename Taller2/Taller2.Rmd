---
title: "Taller2"
author: "Grupo J"
date: "10 de Enero 2022"
output: html_document
---



##INTEGRANTES

Tauma Salvador, Alvaro Cesar 20181160

Echandia Orihuela, Kelly Lidia 20191302

Uriarte Zaga, Aron Salvad0r 20181161

Romero Cuenca, Mary Carmen 20191312

###TALLER2

El archivo seguro.csv contiene datos referidos a pólizas de seguros adquiridas por 200 personas, de las cuales se registran los siguientes atributos:


* age: Edad de la persona

* sex: Sexo de la persona

* bmi: Índice de masa corporal

* children: Número de hijos menores de 12 años

* smoker: Indicador de hábito de fumar (0: No, 1: Sí)

* region: Región de residencia de la persona

* charges: Monto mensual que paga, en dólares


Copie cada una de las preguntas y desarróllelas en un formato Rmd, de modo que genere un archivo HTML

#**0. Ejecute las siguientes tareas de preprocesamiento de datos, utilizando los códigos indicados en el recuadro inferior (requiere la carga previa de paquetes):**




```{r eval=T,echo=T}
library(tidyverse)
```
###LECTURA DE DATOS
```{r eval=T,echo=T}
datos <- read_csv("seguro.csv")
```


**a.** Retire la columna region

**b.** Renombre las columnas como edad, sexo, imc, nhijos, fuma, gastos

**c.** Recodifique las categorías de la variable sexo como masculino y femenino, fuma: sí y no.

```{r}
datos <- datos %>% select(-region) %>%
  rename(edad = 1,sexo = 2,imc = 3,nhijos = 4,fuma = 5,gastos = 6)%>%
  mutate(sexo = recode(sexo, male = "masculino", female = "femenino"),
         fuma = recode(fuma, yes = "si", no = "no"))
```

```{r}
datos
```
```{r}
#################################################################################################
```
```{r}
names(datos)
attach(datos)
```

#**1. Se desea estudiar la influencia lineal de las variables sobre los gastos. Obtenga la estimación puntual de los coeficientes de regresión:**

$$\boldsymbol{\hat{\beta}}= \left(\textbf{X}'\textbf{X}\right)^{-1}\textbf{X}'\textbf{y}$$



**a.** Matricialmente (forme las matrices X e Y, y trabaje con ellas)

```{r}
X <- model.matrix(gastos~edad+sexo+imc+nhijos+fuma,data=datos)

```
$$\left(\textbf{X}'\textbf{X}\right)^{-1}$$
```{r}
C <- solve(t(X)%*%X);C
dim(C) #matriz de dimencion k*k ... k:número de coeficientes de c
t

```


$$\textbf{X}'\textbf{y}$$
```{r}
y <- data.matrix(gastos)
dim(y)
dim(t(X))
t(X)%*%y
```

$$\boldsymbol{\hat{\beta}}= \left(\textbf{X}'\textbf{X}\right)^{-1}\textbf{X}'\textbf{y}$$

```{r}
betasest <- solve(t(X)%*%X)%*%(t(X)%*%y)
```


**b.** Usando el modelo construido con el comando lm
```{r}
library(broom)
modelo <- lm(gastos~ ., data = datos)
modelo |> summary()
```

$$\hat{y}=-5.19529+0.26917x1-0.08941x2+0.25387137x3+0.34643049x4+3.27114117x5$$

#**2. Calcule, utilizando matrices, las sumas de cuadrados de regresión, de error y total.**

```{r}
library(broom)
modelo |> aov() |> summary()
anva <- modelo |> anova();anva
```
###Sumas de cuadrados del total (SCT)

$$\text{SCT}= y^t(I_n-\frac{1}{n} J_n)y$$
$$(I_n-\frac{1}{n} J_n)$$


```{r}
n <- length(gastos);n # cantidad de valores de y
p <- length(names(datos))-1;p# 5variables indp y 1 indep
```

```{r}
#I_n : matriz identidad de n*n
I_n <- diag(n) 

```
```{r}
J_n <- matrix(c(rep(1,n*n)),nrow = n, ncol = n)#J_n : matriz de puro 1s ,dim nxn
#(diag(n)-(1/n)*J_n)%*%y
#dim((1/n)*J_n)
```

```{r eval=F}
matrix(c(rep(1,n*n)),nrow = n, ncol = n)
```
###SUMA DE CUADRADOS DEL TOTAL
```{r}

SCT <- t(y)%*%(I_n-(1/n)*matrix(c(rep(1,n*n)),nrow = n, ncol = n))%*%y;SCT

```

```{r}
SCT<-sum(anva[,2]);SCT
```
###SUMA DE CUADRADOS DE LA REGRESION 

$$\text{SCREG}= y^t(H_{n*n}-\frac{1}{n} J_n)y$$


```{r}
#H_n : matriz hat  identidad de n*n
H <- X%*% solve(t(X)%*%X)%*%(t(X))
dim(H)
```


```{r}
SCREGRE <- t(y)%*%(H-(1/n)*J_n)%*%y;SCREGRE
```
###SUMA DE CUADRADOS DEL ERROR

$$\text{SCERROR}= y^t(I_{n*n}-H_n)y$$
```{r}
SCRERROR <- t(y)%*%(I_n-H)%*%y;SCRERROR
anva[p+1,2]
```

#**3. Obtenga la matriz de varianzas – covarianzas estimadas para el vector de coeficientes de regresión estimados:**



```{r}
#El valor de σ2 es estimado mediante el Cuadrado Medio del Error (sacado del anva)
summary(modelo)$sigma**2 
```
**a**.Matricialmente (utilice la matriz X y obtenga el CME a partir de la pregunta anterior)
```{r}
summary(modelo)$sigma**2*solve(t(X)%*%X)
```
**b.** Usando la función vcov
```{r}
vcov(modelo) 
```

#**4.Muestre una elipse de 96% de confianza para las variables IMC y Número de hijos**

```{r}
library(car)
names(datos)
modelo |> confidenceEllipse(levels     = 0.96,
                            fill       = T,
                            which.coef = c(4,5),
                            col        = "forestgreen")
```

#**5. Escriba el cuadro ANVA, y pruebe la hipótesis de significancia de la regresión con un α = 0.05**


**a.** Utilice el criterio del pvalor

```{r}
modelo <- lm(gastos~ ., data = datos)
modelo %>% summary()
```
 
p-value: < 2.2e-16
**pvalue < 0.05**
Se rechaza H0
Conclusion: Al menos uno de los coeficientes es distinto de 0 lo que implicaria que al menos unas de las variables contribuyen significativa
al modelo

**b.** Utilice el criterio de Fcalculado

```{r}
anva <- modelo |> anova();anva
```
$$F_{calc}>F_{1-\alpha,k-1,n-k}$$
###ANVA
```{r}
k <- length(names(datos));k #numero de coeficientes de regresion betas coicide con el numero de varibales indp y dep (tener cuidado con el codigo!)
n <- length(gastos);n # cantidad de valores de y
p <- length(names(datos))-1;p# 5variables indp y 1 indep

```

###GRADOS DE LIBERTAD
```{r}
GLREGRE <- k-1;GLREGRE
GLERROR <- n-k;GLERROR
GLTOTAL <- n-1;GLTOTAL
```

###SUMA DE CUADRADOS
```{r}
SCREGRE
SCRERROR
SCT
```
###CUADRADOS MEDIOS
```{r}
CMREGRE <- SCREGRE/GLREGRE;CMREGRE
CMERROR <- SCRERROR/GLERROR;CMERROR
```
###FCALCULADO
```{r}
FCALCULADO <- CMREGRE/CMERROR;FCALCULADO
```
```{r}
Fcritico <- qf(1-0.05,k-1,n-k);Fcritico
```

```{r}
FCALCULADO>Fcritico #SI ES CORRECTO H0 SE RECHAZA 

```

#**6. Plantee y desarrolle una prueba de hipótesis para una de las variables predictoras cuantitativas**

```{r}
modelo %>% summary()
```

###Prueba de significancia de  regresión de la varible edad (b1)

$H_0:\beta_1=0$
$H_1:\beta_1\neq0$


(pv< 2e-16) <0.05
Rechaza HO


Conclusion: Si hay contribucion de la varibale edad al modelo o si hay 
efecto lineal de la variable sobre el modelo

#**7.Plantee y desarrolle una prueba de hipótesis para una de las variables predictoras cualitativas.**

###Prueba de significancia de  regresión de la varible sexo (b2)

$H_0:\beta_2=0$
$H_1:\beta_2\neq0$

Fcalculado >alfa
0.914265>0.05
No se rechaza HO

Conclusion: No hay contribucion de la varible sexo al modelo o si hay 
efecto lineal de la variable sobre el modelo


#**8. Plantee una situación donde el punto evaluado para una predicción NO corresponda a una extrapolación**

$$\textbf{x}'\left(\textbf{X}'\textbf{X}\right)^{-1}\textbf{x} > h_{max},\qquad h_{max}=max(h_{11},...,h_{nn})$$

```{r}
x <- c(1,33,1,22.705,0,0)# 33años,masculino,22.705 imc, 0numero de hijos,0 si fuma  
H <- X%*%solve(t(X)%*%X)%*%t(X)#matriz hat
hmax <-  H %>% diag %>% max;hmax
t(x)%*%solve(t(X)%*%X)%*%x
```
```{r}
t(x)%*%solve(t(X)%*%X)%*%x > hmax
```
Notamos que en la verificacion de extrapolacion, la variable h max es mayor, así que no existe extrapolacion. 
Por lo tanto se recomienda hacer estimaciones, ya que la estimación 
resultaria en nuestro rango de datos.

#**9.Plantee una situación donde el punto evaluado para una predicción SÍ corresponda a una extrapolación**

$$\textbf{x}'\left(\textbf{X}'\textbf{X}\right)^{-1}\textbf{x} > h_{max},\qquad h_{max}=max(h_{11},...,h_{nn})$$

```{r}
x = c(1,56,1,18,9,1)# 56años,1 masculino,18 imc, 9 numero de hijos,1 si fuma  
H <- X%*%solve(t(X)%*%X)%*%t(X)#matriz hat
hmax <-  H %>% diag %>% max;hmax
t(x)%*%solve(t(X)%*%X)%*%x

```

```{r}
t(x)%*%solve(t(X)%*%X)%*%x > hmax
```
Conclusión
Notamos que en la verificacion de extrapolacion, h max es menor, asi que sí existe extrapolacion. 
Por lo tanto, no se recomienda hacer estimaciones, ya que la estimación resultaria 
fuera de nuestro rango de datos.


#**10. Verifique si se cumple el supuesto de normalidad de errores**
```{r}
################ NORMALIDAD ###############

library(dplyr)
library(skimr)
library(broom)
library(broom)
modelo |> summary()
modelo |> augment()

(modelo |> residuals() -> residuales)
"HISTOGRAMA"

data.frame(residuales) |> 
  ggplot(aes(x=residuales,))+
  geom_histogram(aes(y =..density..),
                 bins  = 1+3.3*log10(nrow(datos)),
                 fill  = "dodgerblue2",
                 alpha = 0.6)+
  geom_density(size = 1.5)+
  labs(x="Residuales",y="Densidad")+
  theme_minimal()
"CURVA DE DENSIDAD"

data.frame(residuales) |> 
  ggplot(aes(sample=residuales))+
  stat_qq(size = 2) +
  stat_qq_line(distribution = "qnorm")+
  labs(x = "Cuantil teórico",
       y = "Residuales")+
  theme_minimal()

"SIMETRIA Y KURTOSIS"

"Coeficiente de asimetría y curtosis: debe ser igual a 0 y 3, respectivamente"

library(moments)
library(normtest)
residuales |> skewness()

residuales |> skewness.norm.test()

"PV>ALFA NO SE RECHAZA LA HIPOTESIS NULA
EXISTE EVIDENCIAS PARA DECIR QUE LA ASIMETRIA ES 0"

residuales |>  kurtosis()
residuales |>  kurtosis.norm.test()

"PV>ALFA NO SE RECHAZA LA HIPOTESIS NULA
EXISTE EVIDENCIAS PARA DECIR QUE LA KURTOSIS ES 3"

"PRUEBA DE NORMALIDAD"

library(nortest)
residuales |>  shapiro.test()

residuales |>  ad.test()

"ALFA<PVALOR NO SE RECAHZA LA HIPOTESIS NULA EXISTE EVIDENCIA 
PARA DECIR QUE LOS ERRORES PRESENTAN UNA DISTRIBUCION NORMAL"

"QUE TAN BIEN LOS ERRORES SE AJUSTAN A UNA NORMAL"
residuales |>  ks.test("pnorm")
```

#**11.Verifique si se cumple el supuesto de homocedasticidad de errores**
```{r}
####################HOMOCEDASTICIDAD####################

library(ggplot2)

modelo |> augment() |> 
  with(lowess(x = .fitted, y = .resid)) %>% 
  as.data.frame -> smoothed
modelo |> augment() |> 
  ggplot(aes(x=.fitted,y=.resid))+
  geom_point(size = 1.5) + 
  geom_hline(yintercept=0)+
  geom_path(data = smoothed, aes(x = x, y = y), col = "red")+
  labs(x = "Valor ajustado",
       y = "Residual", 
       title = "Evaluación de homocedasticidad",
       subtitle = "Modelo")+
  theme_minimal()

modelo |>  augment() |> 
  ggplot(aes(x=edad,y=.resid))+
  geom_point(size = 1.5) + 
  geom_hline(yintercept=0)+
  labs(x = "edad",
       y = "Residual", 
       title = "Evaluación de homocedasticidad",
       subtitle = "Modelo")+
  theme_minimal() 


modelo |>  augment() |> 
  ggplot(aes(x=sexo,y=.resid))+
  geom_point(size = 3) + 
  geom_hline(yintercept=0)+
  labs(x = "Sexo",
       y = "Residual", 
       title = "Evaluación de homocedasticidad",
       subtitle = "modelo")+
  theme_minimal() 

"En las gráficas vemos las nube de puntos no 
presentan ningún patrón definido, esto quiere decir 
que estamos frente a un rango homocedastico y solo 
en este tipo de rango podemos realizar un análisis de regresión."

"PRUEBA HOMOCEDASTICIDAD"

library(car)
library(olsrr)
library(lmtest)

modelo |> ncvTest()

modelo |> ols_test_breusch_pagan()

"EL PVALOR>ALFA=0.05 EN AMBOS CASOS POR LO TANTO NO SE RHo EXISTE EVIDENCIA
PARA DECIR QUE HAY HOMOGENIDAD DE VARIANZAS"

```
#**12. Verifique si se cumple el supuesto de independencia de errores**

```{r}
########################INDEPENDENCIA#######################

data.frame(residuales) %>% 
  ggplot(aes(x=1:nrow(datos),y=residuales))+
  geom_point(size = 1.5) +
  geom_line()+
  geom_hline(yintercept=0)+
  labs(x = "Orden",
       y = "Residual",
       title = "Evaluación de independencia",
       subtitle = "Modelo")+
  theme_minimal()


#install.packages("ggfortify")
#install.packages("TSA")    
library(TSA)    
library(ggfortify)

residuales %>% 
  TSA::acf(lag = 25, plot=F) %>% 
  autoplot() +
  labs(x = "Desfase",
       y = "Autocorrelación") +
  theme_minimal()

"Notamos algunas observaciones en donde existe una 
autocorrelación (vara>0.4)  en algunos de los desfases se puede 
deducir que el modelo presenta problemas con los residuales."

modelo %>% dwtest(alternative = "two.sided")

"Dado que el PValor>ALFA No se rechaza la Ho por lo tanto 
existe evidencias para decir que los errores son independientes
De la misma manera, en este caso el estadístico de Durbin-Watson
toma el valor 2.0397, próximo a 2 lo que indica la incorrelación de los residuos."

modelo %>%durbinWatsonTest(alternative = "two.sided",
                           max.lag = 10,
                           reps = 1e5)

"El estadístico de Durbin-Watson evalua el grado de
autocorrelación entre el residuo correspondiente a 
cada observación y la anterior. Si su valor está próximo 
a 2, entonces los residuos están incorreladas"

```
#**13. Verifique si se cumple el supuesto de linealidad del modelo**

```{r}
#####################LINEALIDAD#########################

modelo %>% plot(which=1)
 
"Visualmente podemos ver la linea esta aparentemente 
plana, no tiene mucha curvatura por lo que se dira que 
cumple el supuesto de linealidad."

library(car)
modelo |> residualPlots()

"0.95923 es el p-valor de imc a un nivel de significancia, 
se concluye que no se rechaza la hipotesis nula, 
por lo que se cumple el supuesto de linealidad delmodelo

0.09351 es el p-valor de edad a un nivel de significancia(0.05), 
se concluye que no se rechaza la hipotesis nula, 
por lo que se cumple el supuesto de linealidad delmodelo

0.09351 es el p-valor de nhijos a un nivel de significancia(0.05), 
se concluye que no se rechaza la hipotesis nula, 
por lo que se cumple el supuesto de linealidad delmodelo"

modelo |> crPlots()

"Aplica para todas las variables cuantitativas y notamos
que en las graficas, las lineas estan aparentemente planas
por lo que cumple el supuesto de linealidad."

#install.packages("gvlma")
library(gvlma)
modelo |> gvlma()
```






